{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19ae5ad1",
   "metadata": {},
   "source": [
    "![Linear Regression Models](Images/polynomial_regularization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138aa11c",
   "metadata": {},
   "source": [
    "üêá The central problem of all supervised learning (not only linear models) is the **bias‚Äìvariance tradeoff**.  \n",
    "Let‚Äôs find out what this means.\n",
    "\n",
    "---\n",
    "\n",
    "## Bias and Variance\n",
    "\n",
    "Up until now, we have trained models on all available data.  \n",
    "On one hand, this makes sense ‚Äî we want to minimize model errors by using as much data as possible for training.  \n",
    "\n",
    "On the other hand, this approach makes it harder to evaluate how well the model actually performs.  \n",
    "The reason is that if we continue to calculate metrics only on training data, we may find that when the model is applied to unseen data, it performs quite poorly.\n",
    "\n",
    "<div style=\"background-color:#2c2c2c; border:1px solid #555; color:#f0f0f0; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "‚Üí In other words, the model may fit the training set in great detail but fail to capture the general underlying patterns.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Overfitting (High Variance)\n",
    "\n",
    "This problem is called **overfitting**.  \n",
    "Essentially, such a model performs much better on the training data than on new data.  \n",
    "It has become too finely tuned to the unique characteristics of the training set, which are not generalizable patterns.\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Overfitting:</b> Low error on training data, but high error on test (unseen) data.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Underfitting (High Bias)\n",
    "\n",
    "**Underfitting** is the opposite problem.  \n",
    "Here, the model is too weak to capture any meaningful patterns in the data.  \n",
    "As a result, the error is high both on the training data and on the unseen data.\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Underfitting:</b> High error on both training and test data.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0008e5",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/under_over_fit.jpg\" width=\"920\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244bd3e",
   "metadata": {},
   "source": [
    "# Bias and Variance: Theoretical Definitions\n",
    "\n",
    "From a theoretical perspective, **underfitting** and **overfitting** are described by the concepts of **bias** and **variance** of a model.\n",
    "\n",
    "---\n",
    "\n",
    "### Bias (Systematic Error)\n",
    "\n",
    "**Bias** is the expected difference between the true outcome and the model‚Äôs predicted outcome.  \n",
    "In other words, it is the expected error of the model:\n",
    "\n",
    "$\n",
    "bias(\\hat{y}) = M \\big[ (y - \\hat{y}) \\big]\n",
    "$\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> The expectation operator is often denoted as <code>E</code>:  \n",
    "\n",
    "$$\n",
    "bias(\\hat{y}) = E \\big[ (y - \\hat{y}) \\big]\n",
    "$$\n",
    "\n",
    "The larger the bias, the weaker the model.  \n",
    "If the model is weak, it fails to capture patterns in the data ‚Üí this is **underfitting**.\n",
    "\n",
    "---\n",
    "\n",
    "### Variance (Model Instability)\n",
    "\n",
    "**Variance** is the variability of the error, i.e., how much the error will differ if the model is trained on different samples of the data.  \n",
    "Mathematically, this is the **dispersion** (spread) of the model‚Äôs predictions:\n",
    "\n",
    "$$\n",
    "variance(\\hat{y}) = D \\big[ (y - \\hat{y}) \\big]\n",
    "$$\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> Variance is often denoted as <code>Var</code>:  \n",
    "\n",
    "$$\n",
    "variance(\\hat{y}) = Var \\big[ (y - \\hat{y}) \\big]\n",
    "$$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af573f2",
   "metadata": {},
   "source": [
    "# Bias‚ÄìVariance Decomposition of MSE\n",
    "\n",
    "The greater the variance, the more the model‚Äôs error fluctuates across different datasets.  \n",
    "High variance is a sign of **overfitting**: the model adapts too closely to a specific training set and shows unstable predictions on new data.\n",
    "\n",
    "---\n",
    "\n",
    "## Theoretical Decomposition\n",
    "\n",
    "In theory, any loss function can be decomposed into **bias** and **variance** components.  \n",
    "For example, the decomposition of the **mean squared error (MSE)** (its mathematical expectation) looks like this:\n",
    "\n",
    "$$\n",
    "M \\big[ (y - \\hat{y})^2 \\big] = bias(\\hat{y})^2 + variance(\\hat{y}) + \\sigma^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> The expectation of the squared error is the theoretical analogue of MSE:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{n}\n",
    "$$\n",
    "\n",
    "Mathematical expectation is the average across the **entire population** (an infinite dataset), not just a sample.  \n",
    "This makes it a purely theoretical quantity.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Formula breakdown:</b><br>\n",
    "- œÉ¬≤ ‚Äî irreducible error, caused by randomness.<br>\n",
    "- bias(≈∑)¬≤ ‚Äî squared bias of the model.<br>\n",
    "- variance(≈∑) ‚Äî variance (spread) of the model‚Äôs predictions.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## What does this theoretical formula tell us?\n",
    "\n",
    "The total error of the model is composed of:\n",
    "- The squared bias of the model,  \n",
    "- The variance of the model, and  \n",
    "- Random irreducible error.\n",
    "\n",
    "<div style=\"background-color:#2c2c2c; border:1px solid #555; color:#f0f0f0; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "‚Üí We cannot influence the last term œÉ¬≤, but we can act on bias and variance.  \n",
    "Ideally, we want both to approach zero.  \n",
    "However, in practice, reducing one often increases the other.  \n",
    "This is the essence of the <code>bias‚Äìvariance tradeoff</code>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa091e",
   "metadata": {},
   "source": [
    "# The Bias‚ÄìVariance Tradeoff\n",
    "\n",
    "‚Üí We cannot influence the last term ($\\sigma^2$), but we can affect the first two terms (**bias** and **variance**).  \n",
    "Ideally, we would like to reduce both to zero.  \n",
    "However, decreasing one usually increases the other.  \n",
    "In practice, we must balance between biased but stable models and unbiased but unstable ones.\n",
    "\n",
    "---\n",
    "\n",
    "## The Bias‚ÄìVariance Dilemma\n",
    "\n",
    "The **bias‚Äìvariance tradeoff** is the central problem of supervised learning.  \n",
    "Ideally, we want to build a model that accurately captures patterns in training data and also performs well on unseen data.  \n",
    "Unfortunately, this is rarely possible simultaneously.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#5c1e1e; border:1px solid #a33; color:#f0f0f0; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "- Making the model more complex reduces <code>bias</code> but increases the risk of <code>overfitting</code> i.e., higher <code>variance</code>.  \n",
    "- Simpler models tend to have lower <code>variance</code> (less risk of overfitting), but they may fail to capture relationships in the data ‚Üí higher <code>bias</code> (underfitting).\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Analogy: Darts Player üéØ\n",
    "\n",
    "Imagine the model is a darts player:\n",
    "\n",
    "- The **best player** has both low bias and low variance: darts land tightly grouped right at the bullseye.  \n",
    "- A player with **high bias** will have darts clustered together, but away from the bullseye.  \n",
    "- A player with **high variance** will have darts scattered all over the board.  \n",
    "- A **bad model** has both: darts are spread out and not near the bullseye.\n",
    "\n",
    "This analogy shows how **bias** and **variance** interact in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a53d6a",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Images/bias_variance_targets_clean.png\" width=\"720\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda56ad7",
   "metadata": {},
   "source": [
    "# Interesting Fact: Gauss‚ÄìMarkov Theorem\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Interesting fact.</b> According to the <a href=\"https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem\">Gauss‚ÄìMarkov theorem</a>, the estimates of linear regression obtained by the <b>ordinary least squares (OLS)</b> method have the smallest variance.  \n",
    "\n",
    "That is, if there exists another linear model trained by a method different from OLS (e.g., gradient descent), the theorem guarantees that this model will have variance **greater than or equal to** that of the OLS model.  \n",
    "\n",
    "Thus, for linear regression trained with OLS, the risk of overfitting is the lowest.  \n",
    "\n",
    "However, this does not mean that overfitting is impossible at all.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "# From Theory to Practice: How to Detect Bias and Variance?\n",
    "\n",
    "Now that we know the theoretical foundations of underfitting and overfitting, what can we do in practice to judge a model‚Äôs ability to generalize?  \n",
    "How do we diagnose high **bias** and **variance**?\n",
    "\n",
    "The typical solution is to split the data into two parts:  \n",
    "- **Training set** ‚Äî used to train the model and adjust parameters.  \n",
    "- **Test set** ‚Äî unseen by the model during training, used to assess the true quality of the model.\n",
    "\n",
    "This separation allows us to evaluate generalization ability.  \n",
    "Schematically, it can be represented as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931e9c1",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/train_split.png\" width=\"720\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f6c5a",
   "metadata": {},
   "source": [
    "# Let‚Äôs see how this works in practice\n",
    "\n",
    "We‚Äôll use a dataset you already know ‚Äî the **housing** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc2398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np          # matrix computations\n",
    "import pandas as pd         # data analysis & preprocessing\n",
    "import matplotlib.pyplot as plt  # visualization\n",
    "import seaborn as sns       # visualization\n",
    "from sklearn import linear_model  # linear models\n",
    "from sklearn import metrics       # metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9511dfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CRIM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ZN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "INDUS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHAS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NOX",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DIS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RAD",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TAX",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PTRATIO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "B",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "LSTAT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MEDV",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "13d04854-3348-4cb4-bb59-b868c0dc0095",
       "rows": [
        [
         "0",
         "0.00632",
         "18.0",
         "2.31",
         "0",
         "0.538",
         "6.575",
         "65.2",
         "4.09",
         "1",
         "296.0",
         "15.3",
         "396.9",
         "4.98",
         "24.0"
        ],
        [
         "1",
         "0.02731",
         "0.0",
         "7.07",
         "0",
         "0.469",
         "6.421",
         "78.9",
         "4.9671",
         "2",
         "242.0",
         "17.8",
         "396.9",
         "9.14",
         "21.6"
        ],
        [
         "2",
         "0.02729",
         "0.0",
         "7.07",
         "0",
         "0.469",
         "7.185",
         "61.1",
         "4.9671",
         "2",
         "242.0",
         "17.8",
         "392.83",
         "4.03",
         "34.7"
        ],
        [
         "3",
         "0.03237",
         "0.0",
         "2.18",
         "0",
         "0.458",
         "6.998",
         "45.8",
         "6.0622",
         "3",
         "222.0",
         "18.7",
         "394.63",
         "2.94",
         "33.4"
        ],
        [
         "4",
         "0.06905",
         "0.0",
         "2.18",
         "0",
         "0.458",
         "7.147",
         "54.2",
         "6.0622",
         "3",
         "222.0",
         "18.7",
         "396.9",
         "5.33",
         "36.2"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Column names in the dataset\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS',\n",
    "                'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "# Load the Boston housing data (space-separated text)\n",
    "housing_data = pd.read_csv('Data/HousingDataSet.csv',\n",
    "                          header=None,\n",
    "                          delimiter=r\"\\s+\",\n",
    "                          names=column_names)\n",
    "\n",
    "display(housing_data.head())\n",
    "\n",
    "# Build the list of features (exclude the target column)\n",
    "features = housing_data.drop('MEDV', axis=1).columns\n",
    "\n",
    "# Observation matrix X and target vector y\n",
    "X = housing_data[features]\n",
    "y = housing_data['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff636675",
   "metadata": {},
   "source": [
    "# Train/Test Split in `sklearn`\n",
    "\n",
    "In `sklearn`, you can split data into training and test sets with [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from `model_selection`.  \n",
    "The function accepts the following key arguments:\n",
    "\n",
    "- **`X` and `y`** ‚Äî the matrix of examples and the target vector.\n",
    "- **`random_state`** ‚Äî an integer seed used to generate random numbers.  \n",
    "  Both the training and test sets are created randomly. To make your experiment **reproducible**, set this parameter to a fixed value.\n",
    "- **`test_size`** ‚Äî the share of the dataset used for the **test** split.  \n",
    "  Typical choices are **0.3** (70/30 split) or **0.2** (80/20 split).\n",
    "\n",
    "<div style=\"background-color:#2c2c2c; border:1px solid #555; color:#f0f0f0; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Return values (in order):</b> <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, <code>y_test</code>.\n",
    "</div>\n",
    "\n",
    "### Example: Split the Housing data 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964a4aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (354, 13) (354,)\n",
      "Test: (152, 13) (152,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train and test in a 70/30 ratio\n",
    "# Fix random_state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=40\n",
    ")\n",
    "\n",
    "# Show resulting shapes\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:',  X_test.shape,  y_test.shape)\n",
    "\n",
    "# Expected:\n",
    "# Train: (354, 13) (354,)\n",
    "# Test:  (152, 13) (152,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec8df7",
   "metadata": {},
   "source": [
    "- After the split, the training set contains 354 observations and the test set contains 152."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08f95c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.743\n",
      "Test R^2: 0.722\n"
     ]
    }
   ],
   "source": [
    "# Create the LinearRegression model\n",
    "lr_model = linear_model.LinearRegression()\n",
    "\n",
    "# Fit OLS on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test\n",
    "y_train_predict = lr_model.predict(X_train)\n",
    "y_test_predict  = lr_model.predict(X_test)\n",
    "\n",
    "# Report R¬≤\n",
    "print(f\"Train R^2: {round(metrics.r2_score(y_train, y_train_predict), 3)}\")\n",
    "print(f\"Test R^2: {round(metrics.r2_score(y_test, y_test_predict), 3)}\")\n",
    "\n",
    "# Example output:\n",
    "# Train R^2: 0.743\n",
    "# Test  R^2: 0.722"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86c0ba",
   "metadata": {},
   "source": [
    "So, we obtained $R^2 = 0.743$ on the training set and $R^2 = 0.722$ on the test set.  \n",
    "These results are quite close to each other, which indicates a **low variance** (the model‚Äôs predictions are stable across different splits).\n",
    "\n",
    "---\n",
    "\n",
    "This is evidence of the absence of **overfitting**.  \n",
    "Not surprisingly ‚Äî linear regression with 13 features is a rather simple model: only **14 parameters** in total, which is very small by machine learning standards.  \n",
    "The risk of overfitting increases as the number of features grows.\n",
    "\n",
    "---\n",
    "\n",
    "### But what about bias?\n",
    "\n",
    "The simplest way to assess model bias (underfitting) is to look at the metric value and **intuitively evaluate its adequacy**.  \n",
    "\n",
    "Our test score is $R^2 = 0.722$.  \n",
    "This is not a particularly strong result (recall that the maximum is 1).  \n",
    "It may indicate that the model is **too weak**.  \n",
    "\n",
    "One way to address this is to try a more complex model ‚Äî for example, a **polynomial regression**.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> There are more advanced visualization methods for assessing bias and variance, such as the <b>learning curve</b> and <b>cross-validation</b>.  \n",
    "We will cover these later in the course.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf016d4",
   "metadata": {},
   "source": [
    "# Polynomial Features\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Polynomial Regression</b> ‚Äî is a more complex model than linear regression.  \n",
    "Instead of a straight-line equation, it uses a polynomial (multinomial) equation.  \n",
    "The degree of the polynomial can be arbitrarily large: the higher the degree, the more complex the model.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "In the simple two-dimensional case, when we study the dependence of the target variable on a single feature,  \n",
    "a second-degree polynomial gives the equation of a parabola:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_0 + w_1 x + w_2 x^2\n",
    "$$\n",
    "\n",
    "Geometrically, in two-dimensional space, a polynomial is a **curve** that tries to describe the dependence in the data.  \n",
    "It looks like this:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a896b4",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/polynomial_regression.png\" width=\"620\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24fd0fd",
   "metadata": {},
   "source": [
    "When there is more than one feature ‚Äî for example, two ‚Äî then in addition to squaring each feature,  \n",
    "we also get **interaction terms** from $x_1$ and $x_2$:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_0 + w_1 x_1 + w_2 x_1^2 + w_3 x_2 + w_4 x_2^2 + w_5 x_1 x_2\n",
    "$$\n",
    "\n",
    "Such a model describes a **complex surface in three-dimensional space**,  \n",
    "as illustrated in the figure:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a9530b",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/polynomial_surface_3d.png\" width=\"620\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fa465c",
   "metadata": {},
   "source": [
    "Notice how quickly the **number of coefficients** grows ‚Äî and with it, the **complexity of the model**.  \n",
    "And that‚Äôs just with two features ($x_1$ and $x_2$).  \n",
    "We won‚Äôt write out the general polynomial equation (as we did for linear regression),  \n",
    "because it would contain too many terms.\n",
    "\n",
    "---\n",
    "\n",
    "For example, when we previously plotted the relationship between the **median housing price** and the **percentage of lower-status population**,  \n",
    "you might have noticed that the relationship is not linear, but rather **polynomial** in nature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842be3a",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/linear_vs_polynomial_regression.png\" width=\"620\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d3d28",
   "metadata": {},
   "source": [
    "In the figure, you can see models of **linear regression** and **polynomial regression (degree 2)**.\n",
    "\n",
    "---\n",
    "\n",
    "Notice that the powers of $x$ can also be considered as a kind of **artificial features** in the data.  \n",
    "They are called **polynomial features**.\n",
    "\n",
    "Therefore, polynomial regression is essentially the same linear regression, just with **new features**.  \n",
    "Polynomial features are one of the most widely used methods of **feature engineering**.\n",
    "\n",
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483666de",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/polynomial_features_tables.png\" width=\"720\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚Üí Thanks to polynomial terms, the model becomes **more complex** and begins to capture more complicated dependencies,  \n",
    "resulting in **lower bias**.  \n",
    "However, as you might guess, the risk of **overfitting** increases sharply ‚Äî the variance of predictions grows with the number of factors.\n",
    "\n",
    "---\n",
    "\n",
    "## Polynomial Regression in `sklearn`\n",
    "\n",
    "Building a polynomial regression in `sklearn` is straightforward.  \n",
    "We first need to create polynomial features using the class [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) from the `preprocessing` module.  \n",
    "\n",
    "This transformer generates polynomial features of any degree and adds them to the dataset.  \n",
    "It has two key parameters:\n",
    "\n",
    "- **`degree`** ‚Äî the degree of the polynomial. Default is `2`.\n",
    "- **`include_bias`** ‚Äî whether to include a column of ones ($x^0$) in the resulting feature set.  \n",
    "  Default is `True`, but it‚Äôs often better to set it to `False` because the column of ones is already added in OLS regression.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> In practice, data scientists usually stop at a polynomial of degree 2 (or at most degree 3).  \n",
    "The higher the degree, the more terms are generated, which means more features and a more complex model.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "To fit the generator and calculate the number of polynomial feature combinations, we use the method **`.fit()`**.  \n",
    "To actually generate the new feature table (with polynomial features included), we use **`.transform()`**, passing in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a39250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 104)\n",
      "(152, 104)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Create the polynomial feature generator\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Fit on the training data (learns the combinations schema)\n",
    "poly.fit(X_train)\n",
    "\n",
    "# Generate polynomial features for train and test\n",
    "X_train_poly = poly.transform(X_train)\n",
    "X_test_poly  = poly.transform(X_test)\n",
    "\n",
    "# Show resulting shapes\n",
    "print(X_train_poly.shape)\n",
    "print(X_test_poly.shape)\n",
    "\n",
    "# Expected:\n",
    "# (354, 104)\n",
    "# (152, 104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7255a9",
   "metadata": {},
   "source": [
    "So, we generated new **training** and **test** datasets.  \n",
    "In each table, in addition to the 13 original features, we now have **91 polynomial combinations of degree 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5697428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_poly))\n",
    "print(type(X_test_poly))\n",
    "# <class 'numpy.ndarray'>\n",
    "# <class 'numpy.ndarray'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c49d9",
   "metadata": {},
   "source": [
    "As a result, we obtained two **NumPy arrays**:\n",
    "\n",
    "- `X_train_poly` ‚Äî training features (354 √ó 104)  \n",
    "- `X_test_poly` ‚Äî test features (152 √ó 104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c19814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.929\n",
      "Test  R^2: 0.268\n"
     ]
    }
   ],
   "source": [
    "# Create the LinearRegression model\n",
    "lr_model_poly = linear_model.LinearRegression()\n",
    "\n",
    "# Fit OLS on polynomial features\n",
    "lr_model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_predict_poly = lr_model_poly.predict(X_train_poly)\n",
    "y_test_predict_poly  = lr_model_poly.predict(X_test_poly)\n",
    "\n",
    "# R¬≤ on train and test\n",
    "print(f\"Train R^2: {metrics.r2_score(y_train, y_train_predict_poly):.3f}\")\n",
    "print(f\"Test  R^2: {metrics.r2_score(y_test,  y_test_predict_poly):.3f}\")\n",
    "\n",
    "# Example output:\n",
    "# Train R^2: 0.929\n",
    "# Test  R^2: 0.268"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5825575",
   "metadata": {},
   "source": [
    "Amazing! On the training set, the coefficient of determination is $R^2 = 0.929$,  \n",
    "which means our model explains almost **93%** of the variance in the data.  \n",
    "\n",
    "But when we look at the test set results, we come crashing down: $R^2 = 0.268$.  \n",
    "This metric is much lower than on the training set.  \n",
    "This is a clear case of **overfitting**: due to its complexity (large number of features),  \n",
    "the model has fully adapted to the training data but shows very high variance on data it has never seen before.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> A linear regression model can also be unstable even if train and test scores are close,  \n",
    "because the regression coefficients themselves may take extremely large values.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Such a model is practically useless, since it does not reflect reality.  \n",
    "\n",
    "But don‚Äôt worry ‚Äî there is a powerful method that can save our model from overfitting:  \n",
    "**regularization**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bd83c",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Regularization</b> ‚Äî a method for reducing overfitting in machine learning models.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "The idea of regularization is that we intentionally **increase the bias** of the model in order to **reduce variance**.  \n",
    "This is the **law of balance** in action!\n",
    "\n",
    "But how can we increase the bias of a model?  \n",
    "We can *‚Äúpenalize‚Äù* the model for learning overly complex relationships.\n",
    "\n",
    "Mathematically, this is done by adding a **penalty term** to the loss function.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Penalty</b> ‚Äî an additional non-negative term in the loss function expression,  \n",
    "which deliberately increases the error.  \n",
    "\n",
    "Thanks to this term, the optimization method (OLS or SGD) no longer finds the *true* minimum of the loss function,  \n",
    "but instead converges to a **pseudo-minimum** that balances fit and model complexity.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2782f3",
   "metadata": {},
   "source": [
    "There are several ways to add a **penalty term** to the loss function:\n",
    "\n",
    "---\n",
    "\n",
    "- **L1 Regularization (Lasso)** ‚Äî adds the sum of the absolute values of the coefficients,  \n",
    "  multiplied by the regularization parameter $\\alpha$:\n",
    "\n",
    "$$\n",
    "L_{1}(w) = MSE + \\alpha \\sum_{j=1}^{m} |w_j|\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "- **L2 Regularization (Ridge), or Tikhonov Regularization** ‚Äî adds the sum of the squares of the coefficients,  \n",
    "  multiplied by the regularization parameter $\\alpha$:\n",
    "\n",
    "$$\n",
    "L_{2}(w) = MSE + \\alpha \\sum_{j=1}^{m} (w_j)^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Regularization coefficient &alpha;</b> ‚Äî controls how much bias we introduce into the model.  \n",
    "The larger &alpha;, the stronger the penalty for overfitting.\n",
    "</div>\n",
    "\n",
    "### Geometric Interpretation of Regularization\n",
    "\n",
    "What about the **geometry**?  \n",
    "Let‚Äôs consider how the minimum of the loss function looks in 3D space (top view).\n",
    "\n",
    "- With **L1 regularization** $L_1(w)$, the minimum is found at the intersection with a **diamond-shaped constraint**.\n",
    "- With **L2 regularization** $L_2(w)$, the minimum is found at the intersection with a **circular constraint**.\n",
    "\n",
    "Visualization is shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377da84",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"Images/l1_l2_regularization.ppm\" width=\"720\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adeb554",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"Images/l1_l2_regul_graph.png\" width=\"420\" alt=\"Gradient descent illustration\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d336927",
   "metadata": {},
   "source": [
    "## Geometric view of regularization: where does the minimum come from?\n",
    "\n",
    "The figures above illustrate solving the loss-minimization problem.\n",
    "\n",
    "### For the **right** figure (L1):\n",
    "$$\n",
    "L_{1}(w)=\\frac{\\sum_{i=1}^{n}\\left(y_i-w_0-w_1x_1\\right)^2}{n}\n",
    "\\;+\\; \\alpha\\left(\\,|w_0|+|w_1|\\,\\right)\\;\\;\\to\\;\\min_{w}\n",
    "$$\n",
    "\n",
    "### For the **left** figure (L2):\n",
    "$$\n",
    "L_{2}(w)=\\frac{\\sum_{i=1}^{n}\\left(y_i-w_0-w_1x_1\\right)^2}{n}\n",
    "\\;+\\; \\alpha\\left(\\,(w_0)^2+(w_1)^2\\,\\right)\\;\\;\\to\\;\\min_{w}\n",
    "$$\n",
    "\n",
    "The concentric circles (level sets) depict the MSE loss  \n",
    "$$\n",
    "MSE=\\frac{\\sum_{i=1}^{n}(y_i-\\hat y_i)^2}{n}.\n",
    "$$\n",
    "The extra regularization terms define constraint curves:\n",
    "- $\\lambda_1=\\alpha(|w_0|+|w_1|)$ ‚Äî a **diamond** (L1),\n",
    "- $\\lambda_2=\\alpha\\big((w_0)^2+(w_1)^2\\big)$ ‚Äî a **circle** (L2).\n",
    "\n",
    "Thus, after adding the penalty $\\lambda$, we no longer take the true unconstrained minimum, but a **pseudo-minimum** at the **intersection** of the MSE level set with the diamond (for L1) or the circle (for L2).  \n",
    "This is **constrained optimization**, typically derived via the **method of Lagrange multipliers**.\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note.</b> In <code>sklearn</code>, these optimization problems are solved with an iterative\n",
    "<a href=\"https://scikit-learn.org/stable/modules/linear_model.html#lasso\">coordinate descent</a> algorithm (conceptually similar in spirit to gradient methods, but updating one coordinate at a time rather than using full gradients).\n",
    "</div>\n",
    "\n",
    "### Why L1 is special (sparsity)\n",
    "A distinctive property of **L1** regularization is that coefficients for ‚Äúunnecessary‚Äù features are driven **exactly to zero**.\n",
    "Those features drop out of the prediction entirely.  \n",
    "This is crucial for complex models with many inputs (e.g., our 91 extra polynomial features): by shrinking the model and inducing sparsity, we reduce variance ‚Äî and therefore **mitigate overfitting**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80faaa07",
   "metadata": {},
   "source": [
    "In conclusion to the theoretical part, it‚Äôs worth noting that in practice, we never know in advance which regularization method will work best.  \n",
    "**The solution:** try both methods and compare results.\n",
    "\n",
    "---\n",
    "\n",
    "## Time to move on to practice!\n",
    "\n",
    "Experience shows that training linear regression models with many features is recommended on **standardized (normalized) data**.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note:</b> A common question is: <b>how should we standardize/normalize when we have both training and test sets?</b>  \n",
    "\n",
    "You must <b>fit</b> the transformation <b>only on the training set</b>, and then use it (with the same parameters) to <b>transform</b> both the training and test sets.  \n",
    "If you fit separately on each set, you will introduce bias into the model.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Standardization (normalization) is best done **before generating polynomial features**, otherwise we risk losing scale consistency across polynomials.\n",
    "\n",
    "Let‚Äôs preprocess our data now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8408fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 104)\n",
      "(152, 104)\n"
     ]
    }
   ],
   "source": [
    "## Standardize ‚Üí Generate Polynomial Features (degree=2)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# INitialize the scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Fit scaler on the Train set only (learns the scaling parameters from the training data such as mean and std deviation)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform (i.e., standardize) train and test with the same scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Create polynomial feature generator (degree=2, no bias column)\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(X_train_scaled)\n",
    "\n",
    "# Generate polynomial features for train and test\n",
    "X_train_scaled_poly = poly.transform(X_train_scaled)\n",
    "X_test_scaled_poly  = poly.transform(X_test_scaled)\n",
    "\n",
    "# Check shapes\n",
    "print(X_train_scaled_poly.shape)\n",
    "print(X_test_scaled_poly.shape)\n",
    "\n",
    "# Expected:\n",
    "# (354, 104)\n",
    "# (152, 104)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098d2d5",
   "metadata": {},
   "source": [
    "‚Üí In **sklearn**, regularization methods are implemented in the classes  \n",
    "[`Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) (L1 regularization) and  \n",
    "[`Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) (L2 regularization).  \n",
    "\n",
    "Both methods search for parameters with an added regularization penalty.  \n",
    "The training and prediction process looks the same as for ordinary linear regression.\n",
    "\n",
    "---\n",
    "\n",
    "## Train a Lasso Regression Model\n",
    "\n",
    "Now let‚Äôs build a **linear regression with L1 regularization (Lasso)**  \n",
    "using the polynomial features we generated earlier.\n",
    "\n",
    "The main initialization parameter of `Lasso` is **`alpha`** (regularization strength).  \n",
    "- Default: `alpha=1`.  \n",
    "- In practice, this is often **too strong** for L1.  \n",
    "\n",
    "Let‚Äôs set `alpha=0.1` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60e4101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.879\n",
      "Test  R^2: 0.882\n"
     ]
    }
   ],
   "source": [
    "# L1-regularized linear regression (Lasso)\n",
    "lasso_lr_poly = linear_model.Lasso(alpha=0.1)\n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "y_test_predict_poly  = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "\n",
    "# R¬≤ on train/test\n",
    "print(f\"Train R^2: {metrics.r2_score(y_train, y_train_predict_poly):.3f}\")\n",
    "print(f\"Test  R^2: {metrics.r2_score(y_test,  y_test_predict_poly):.3f}\")\n",
    "\n",
    "# Example output:\n",
    "# Train R^2: 0.879\n",
    "# Test  R^2: 0.882"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec7d79",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c2c2c; border:1px solid #555; color:#f0f0f0; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Notice how the metrics have changed:</b><br>\n",
    "- On the training set: R¬≤ = 0.879. The score decreased (before standardization + regularization it was R¬≤ = 0.929).<br>\n",
    "- On the test set: R¬≤ = 0.882. The score increased significantly (before it was only R¬≤ = 0.268).<br><br>\n",
    "üëâ We successfully overcame <b>overfitting</b>.\n",
    "</div>\n",
    "\n",
    "Now let‚Äôs output the model‚Äôs coefficient values, rounded to three decimal places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc911a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.     0.    -0.038  0.    -0.523  2.766 -0.355 -0.605  0.    -0.595\n",
      " -0.763  0.    -3.259 -0.    -0.     0.     3.132 -0.141  0.     0.\n",
      "  0.    -0.     0.     0.    -0.015 -0.     0.063 -0.    -0.     0.\n",
      "  0.159 -0.    -0.    -0.     0.     0.07  -0.    -0.     0.017  0.\n",
      "  0.    -0.     0.     0.     0.     0.    -0.    -0.     0.     0.46\n",
      " -0.808 -0.643  0.    -0.    -0.     0.    -0.     0.    -0.43  -0.348\n",
      " -0.511 -0.     0.    -0.14  -0.    -0.277  0.    -0.     0.223 -0.\n",
      " -0.    -0.836 -0.054 -0.421  0.019 -0.784  0.    -0.     0.706  0.\n",
      " -0.    -0.335 -0.198  0.    -0.     0.     0.205 -0.     0.531 -0.\n",
      "  0.     0.048 -0.    -0.292  0.677  0.81  -0.    -1.151 -0.    -0.\n",
      " -0.    -0.288 -0.356  0.429]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(lasso_lr_poly.coef_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912f612",
   "metadata": {},
   "source": [
    "> **Note:** Pay attention: most of the coefficients have become zero. This means that the features corresponding to these coefficients are not used in the prediction of the Lasso regression model.\n",
    "\n",
    "Now let‚Äôs train a linear regression model with L2 regularization on the same data.  \n",
    "For L2 regularization, the parameter `alpha` is 1 by default. Let‚Äôs try using the parameter value `alpha=10`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca1c4356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.907\n",
      "Test R^2: 0.848\n"
     ]
    }
   ],
   "source": [
    "# Create an object of the linear regression class with L2 regularization\n",
    "ridge_lr_poly = linear_model.Ridge(alpha=10)\n",
    "\n",
    "# Train the model\n",
    "ridge_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "\n",
    "# Make predictions for the training set\n",
    "y_train_predict_poly = ridge_lr_poly.predict(X_train_scaled_poly)\n",
    "\n",
    "# Make predictions for the test set\n",
    "y_test_predict_poly = ridge_lr_poly.predict(X_test_scaled_poly)\n",
    "\n",
    "# Calculate the coefficient of determination for both sets\n",
    "print(f'Train R^2: {round(metrics.r2_score(y_train, y_train_predict_poly), 3)}')\n",
    "print(f'Test R^2: {round(metrics.r2_score(y_test, y_test_predict_poly), 3)}')\n",
    "\n",
    "# Train R^2: 0.907\n",
    "# Test R^2: 0.831"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e398b22",
   "metadata": {},
   "source": [
    "The values of the metric $R^2$ on the test set for `L1-regularization` turned out to be slightly `higher`.  \n",
    "First of all, we always focus on the test set ‚Äî these are the data the model has not seen before.\n",
    "\n",
    "Let‚Äôs now output the values of the model coefficients, rounding them to the third decimal place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b53de5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.128 -0.049  0.084  0.117 -0.932  2.848 -1.008 -1.464  0.909 -0.908\n",
      " -0.653  0.971 -2.605  0.085 -0.032  0.466  2.721 -0.507  0.986  0.309\n",
      " -0.391 -0.714  0.376 -0.379  0.072  0.287  0.143 -0.138 -0.014  0.315\n",
      "  0.05  -0.409 -0.316  0.075  0.702  0.08  -0.281 -0.37   0.511  0.175\n",
      "  0.72   0.282  0.477  0.888 -0.012  0.074 -0.052  0.166 -0.263  0.414\n",
      " -1.129 -0.852  0.273  0.227 -0.106  0.368 -0.137 -0.241 -0.697 -0.177\n",
      " -0.326 -0.524  0.882 -0.637  0.344 -0.439 -0.006  0.386  0.233 -0.535\n",
      "  0.111 -0.802 -0.662 -0.56   0.22  -1.001  0.123  0.144  0.889 -0.114\n",
      " -0.086 -1.022 -0.71   1.08  -0.446 -0.178 -0.07  -0.496  0.874 -0.926\n",
      "  0.717  0.601 -0.49  -0.723  0.308  1.086 -0.448 -1.256  0.057  0.354\n",
      " -0.059 -0.433 -0.791  0.177]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(ridge_lr_poly.coef_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cee9b5",
   "metadata": {},
   "source": [
    "It can be seen that L2-regularization does not zero out coefficients ‚Äî it uses `ALL` features for prediction.\n",
    "\n",
    "> The parameter `alpha` is very important: the choice of its value determines how strongly we penalize the model for overfitting.  \n",
    "> It is important to find the value that gives the best effect.  \n",
    "> Try manually changing the parameter `alpha` for the models built earlier. Agree, this is not very convenient.\n",
    "\n",
    "Let‚Äôs organize a process for iterating over model parameters: we‚Äôll create a loop in which we will iterate over 20 different values of `alpha` in the range from 0.001 to 1.  \n",
    "The easiest way to create such a list is with the `linspace()` function from the **numpy** library.\n",
    "\n",
    "In the loop, we will train a linear regression model with L1-regularization (Lasso), compute the metric $R^2$ values on the training and test sets, and store the results in the lists `train_scores` and `test_scores`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7dc9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of 20 possible values from 0.001 to 1 (that will be evenly spread)\n",
    "alpha_list = np.linspace(0.001, 1, 20)\n",
    "\n",
    "# Create empty lists to store results\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    # Create a linear regression object with L1 regularization (Lasso)\n",
    "    lasso_lr_poly = linear_model.Lasso(alpha=alpha, max_iter=10000)  \n",
    "    # Train the model  \n",
    "    lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "    # Make predictions for the training set\n",
    "    y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "    # Make predictions for the test set\n",
    "    y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "    # Compute R¬≤ for both sets and append to the lists\n",
    "    train_scores.append(round(metrics.r2_score(y_train, y_train_predict_poly), 3))\n",
    "    test_scores.append(round(metrics.r2_score(y_test, y_test_predict_poly), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462f322",
   "metadata": {},
   "source": [
    "As a result of running this code, the lists `train_scores` and `test_scores` will contain 20 different $R^2$ values on the training and test sets.\n",
    "\n",
    "Let‚Äôs plot line charts to show how the $R^2$ metric on the training and test sets changes as a function of `alpha`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd6e204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.plot(alpha_list, train_scores, marker='o', linewidth=2, label='Train')\n",
    "ax.plot(alpha_list, test_scores,  marker='s', linewidth=2, label='Test')\n",
    "\n",
    "# Highlight best alpha on Test\n",
    "i = int(np.nanargmax(test_scores)) # finds the index of the max value in test_scores, ignoring NaNs, and stores it as an int.\n",
    "ax.scatter(alpha_list[i], test_scores[i], s=60, zorder=3)\n",
    "ax.annotate(f'best Œ±={alpha_list[i]:.3g}\\nR¬≤={test_scores[i]:.3f}',\n",
    "            xy=(alpha_list[i], test_scores[i]),\n",
    "            xytext=(8, 8), textcoords='offset points')\n",
    "\n",
    "ax.set_title('R¬≤ vs Regularization Œ±')\n",
    "ax.set_xlabel('Œ±')\n",
    "ax.set_ylabel('R¬≤')\n",
    "\n",
    "# PAY ATTENTION HERE: we use the values for the x-axis from the alpha_list that we generated above. In other words, it contains alphas that we used to generate or maximum values of R^2\n",
    "ax.set_xticks(alpha_list.round(4))          # 0.00, 0.05, ..., 1.00\n",
    "ax.set_xlim(0, 1)  \n",
    "\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "for s in ('top', 'right'):\n",
    "    ax.spines[s].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79c94c",
   "metadata": {},
   "source": [
    "Using the graph, we can select the optimal value of the parameter `alpha`.  \n",
    "We need the point on the x-axis where the test set shows the maximum metric, and at the same time, the difference between the metrics on the training and test sets is minimal.  \n",
    "\n",
    "It is clear that $R^2$ on the test set reaches its maximum value at the point `0.0536`.  \n",
    "At this point, the metrics on both datasets are approximately equal. Beyond this, the metric on the test set begins to decrease.  \n",
    "\n",
    "Note that on the training set, $R^2$ continuously decreases as `alpha` increases.  \n",
    "This makes sense: the larger the `alpha`, the stronger the regularization, and the less the model adapts to the training set.  \n",
    "\n",
    "Now let‚Äôs substitute the value `alpha = 0.0536` into the Lasso model and get the result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96004a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.894\n",
      "Test R^2: 0.890\n"
     ]
    }
   ],
   "source": [
    "# Create a linear regression object with L1 regularization\n",
    "lasso_lr_poly = linear_model.Lasso(alpha=0.0536)\n",
    "# Train the model\n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "# Make predictions for the training set\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "# Make predictions for the test set\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "# Calculate the coefficient of determination for both sets\n",
    "print(f\"Train R^2: {metrics.r2_score(y_train, y_train_predict_poly):.3f}\")\n",
    "print(f\"Test R^2: {metrics.r2_score(y_test, y_test_predict_poly):.3f}\")\n",
    "\n",
    "# Train R^2: 0.894\n",
    "# Test R^2: 0.890"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb15b8",
   "metadata": {},
   "source": [
    "So, the $R^2$ metric increased because we were able to find the optimal value of the parameter `alpha`.\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note.</b> In addition to the basic regularization methods <i>L1</i> and <i>L2</i>, there is also a combined method.\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Elastic Net</b> ‚Äî a combination of both regularization methods.  \n",
    "The loss function in this method is expressed as follows:\n",
    "\n",
    "$$\n",
    "L_2(w) = MSE + \\alpha \\cdot \\lambda \\sum_{i=1}^{m} |w_i| + \\alpha \\cdot (1 - \\lambda) \\sum_{i=1}^{m} (w_i)^2 \\rightarrow \\min_{w}\n",
    "$$\n",
    "</div>\n",
    "\n",
    "In <code>sklearn</code>, the Elastic Net implementation is available in the <code>ElasticNet</code> class.  \n",
    "The parameters `alpha` and `lambda` allow you to control the contribution of <i>L1</i> and <i>L2</i> regularization.  \n",
    "In practice, this method is used less frequently since it requires selecting an optimal combination of two parameters.\n",
    "\n",
    "<div style=\"background-color:#1e4620; border:1px solid #2e7d32; color:#e0f2e9; padding:12px; border-radius:6px; margin:12px 0;\">\n",
    "<b>Note.</b> Regularization is also present in the <code>SGDRegressor</code> model and is used by default.  \n",
    "In the class initializer, there is a parameter <code>penalty</code>, which determines the type of regularization.  \n",
    "The parameter can take the values <code>'l1'</code>, <code>'l2'</code>, or <code>'elasticnet'</code>.  \n",
    "By default, the <i>L2</i>-regularization (<code>penalty='l2'</code>) is used.  \n",
    "The regularization coefficient (<code>alpha</code>) defaults to <code>0.0001</code> (a relatively weak regularization).  \n",
    "By adjusting these two parameters, you can control both the type and ‚Äústrength‚Äù of regularization in the <code>SGD</code> method.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
