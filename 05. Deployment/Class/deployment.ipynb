{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0886d3",
   "metadata": {},
   "source": [
    "The first code snippet contains all the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6824de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6bae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/data-week-3.csv', <http.client.HTTPMessage at 0x1e93faf3230>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv\"  # replace with your actual $data link\n",
    "urllib.request.urlretrieve(url, \"data/data-week-3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7295c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    " \n",
    "df = pd.read_csv('data/data-week-3.csv')\n",
    " \n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    " \n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    " \n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    " \n",
    "df.totalcharges = pd.to_numeric(df.totalcharges, errors='coerce')\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    " \n",
    "df.churn = (df.churn == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4c493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    " \n",
    "df_full_train, df_test = train_test_split(df, \n",
    "                                          test_size=0.2, \n",
    "                                          random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163f7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['tenure', 'monthlycharges', 'totalcharges']\n",
    " \n",
    "categorical = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "       'phoneservice', 'multiplelines', 'internetservice',\n",
    "       'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',\n",
    "       'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',\n",
    "       'paymentmethod']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597e2e8",
   "metadata": {},
   "source": [
    "The next snippet is about the train function. It has three arguments â€“ the training dataframe and the target values y_train, and the third argument is C which is a LogisticRegression parameter for our model. First step here is to create dictionaries from the categorical columns, remember the numerical columns are ignored here. Next we create a DictVectorizer instance which we need to use fit_transform function on the dictionaries. So we get the X_train. Then we create our model which is a logistic regression model, that we can use for training (fit function) based on the training data (X_train and y_train). To apply the model later we need to return the DictVectorizer and the model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd4dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    " \n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    " \n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    " \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b5cf1",
   "metadata": {},
   "source": [
    "As I just mentioned in the paragraph before to use the model we need also the DictVectorizer. Both are arguments for the predict function which is show in the next snippet. Besides both arguments you also need a dataframe where we can provide a prediction for. First step here is the same like in training function, we need to get the dictionaries. This can be transformed by the DictVectorizer so we get the X, what we need to make a prediction on. What we return here is the predicted probability for churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff217e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "     dicts = df[categorical + numerical].to_dict(orient='records')\n",
    " \n",
    "     X = dv.transform(dicts)\n",
    "     y_pred = model.predict_proba(X)[:,1]\n",
    " \n",
    "     return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
